{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrisMcode111/DI_Bootcamp/blob/main/w8_d3_XP_Open_Source_LLMs_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1c067d",
      "metadata": {
        "id": "be1c067d"
      },
      "source": [
        "# Exercises XP: Open-Source LLM Strategy (Student)\n",
        "Use this guided notebook and fill each TODO. Run it in Colab if you prefer; GPU not required unless you try optional model runs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25420a9",
      "metadata": {
        "id": "b25420a9"
      },
      "source": [
        "## What you'll learn\n",
        "- Identify degrees of openness in LLMs and what each enables.\n",
        "- Understand and compare open-source licenses.\n",
        "- Assess strengths/trade-offs of open LLMs for specific constraints (CPU, math, multilingual).\n",
        "- Evaluate which models fit given hardware and licensing needs.\n",
        "- Use open tools/leaderboards to guide model selection.\n",
        "- Plan deployment trade-offs (local vs. cloud)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c12bf3e",
      "metadata": {
        "id": "5c12bf3e"
      },
      "source": [
        "## What you will create\n",
        "- Comparative LLM openness analysis (table + paragraph + healthcare prompt answer).\n",
        "- Licensing compatibility checklist for SaaS products.\n",
        "- Quiz-style reflection on LLM selection.\n",
        "- Local deployment readiness checklist + upgrade notes.\n",
        "- Benchmark-based model match guide.\n",
        "- Hardware upgrade plan / cost-benefit comparison (local vs. cloud)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06137b8f",
      "metadata": {
        "id": "06137b8f"
      },
      "source": [
        "## Exercise 1: Open Source Levels Reflection\n",
        "**Use:** Fully Open, Weights Released, Architecture Only; model components; fine-tuning/domain adaptation; healthcare compliance.\n",
        "\n",
        "**Step-by-step**\n",
        "1) Gather definitions for the three openness levels.  \n",
        "2) Identify key characteristics (what is open; what you can/cannot do).  \n",
        "3) Compare side by side in a table (what's open vs. impact).  \n",
        "4) Write a 3?5 sentence comparative paragraph.  \n",
        "5) Answer the healthcare prompt (1?2 sentences) about retraining on clinical data.\n",
        "\n",
        "**Deliverables:** paragraph + healthcare answer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_source_levels = {\n",
        "    \"Fully Open\": {\n",
        "        \"definition\": \"A fully open-source model where code, architecture, weights, and training data (partially or fully) are released under a permissive license that allows use, modification, and redistribution.\",\n",
        "        \"what_is_open\": [\n",
        "            \"Model weights\",\n",
        "            \"Model architecture\",\n",
        "            \"Source code\",\n",
        "            \"Training data (partial or full)\"\n",
        "        ],\n",
        "        \"what_you_can_do\": [\n",
        "            \"Run the model locally without restrictions\",\n",
        "            \"Retrain or fine-tune on domain-specific data\",\n",
        "            \"Modify, redistribute, or commercialize the model\"\n",
        "        ],\n",
        "        \"what_you_cannot_do\": [\n",
        "            \"Few limitations beyond respecting the license\",\n",
        "            \"No major commercial restrictions in most cases\"\n",
        "        ],\n",
        "    },\n",
        "\n",
        "    \"Weights Released\": {\n",
        "        \"definition\": \"The model’s pre-trained weights are publicly released, usually along with the architecture, but training data and full source code may remain closed.\",\n",
        "        \"what_is_open\": [\n",
        "            \"Pre-trained model weights\",\n",
        "            \"Model architecture\"\n",
        "        ],\n",
        "        \"what_you_can_do\": [\n",
        "            \"Use the model directly\",\n",
        "            \"Perform fine-tuning on custom data\"\n",
        "        ],\n",
        "        \"what_you_cannot_do\": [\n",
        "            \"Access the original training data\",\n",
        "            \"Freely redistribute or commercially exploit the model if the license restricts it\"\n",
        "        ],\n",
        "    },\n",
        "\n",
        "    \"Architecture Only\": {\n",
        "        \"definition\": \"Only the high-level model architecture is released; no weights or usable training artifacts are provided. Useful for research but not for immediate deployment.\",\n",
        "        \"what_is_open\": [\n",
        "            \"Theoretical model design\",\n",
        "            \"Architecture description\"\n",
        "        ],\n",
        "        \"what_you_can_do\": [\n",
        "            \"Rebuild the model from scratch\",\n",
        "            \"Train it entirely on your own data (high cost)\"\n",
        "        ],\n",
        "        \"what_you_cannot_do\": [\n",
        "            \"Use the model as-is (no weights available)\",\n",
        "            \"Replicate original performance without extensive training resources\"\n",
        "        ],\n",
        "    },\n",
        "}\n",
        "\n",
        "open_source_levels\n"
      ],
      "metadata": {
        "id": "e_neTYqIbF5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d23855f-a717-48af-a78c-c54976bc448d"
      },
      "id": "e_neTYqIbF5J",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Fully Open': {'definition': 'A fully open-source model where code, architecture, weights, and training data (partially or fully) are released under a permissive license that allows use, modification, and redistribution.',\n",
              "  'what_is_open': ['Model weights',\n",
              "   'Model architecture',\n",
              "   'Source code',\n",
              "   'Training data (partial or full)'],\n",
              "  'what_you_can_do': ['Run the model locally without restrictions',\n",
              "   'Retrain or fine-tune on domain-specific data',\n",
              "   'Modify, redistribute, or commercialize the model'],\n",
              "  'what_you_cannot_do': ['Few limitations beyond respecting the license',\n",
              "   'No major commercial restrictions in most cases']},\n",
              " 'Weights Released': {'definition': 'The model’s pre-trained weights are publicly released, usually along with the architecture, but training data and full source code may remain closed.',\n",
              "  'what_is_open': ['Pre-trained model weights', 'Model architecture'],\n",
              "  'what_you_can_do': ['Use the model directly',\n",
              "   'Perform fine-tuning on custom data'],\n",
              "  'what_you_cannot_do': ['Access the original training data',\n",
              "   'Freely redistribute or commercially exploit the model if the license restricts it']},\n",
              " 'Architecture Only': {'definition': 'Only the high-level model architecture is released; no weights or usable training artifacts are provided. Useful for research but not for immediate deployment.',\n",
              "  'what_is_open': ['Theoretical model design', 'Architecture description'],\n",
              "  'what_you_can_do': ['Rebuild the model from scratch',\n",
              "   'Train it entirely on your own data (high cost)'],\n",
              "  'what_you_cannot_do': ['Use the model as-is (no weights available)',\n",
              "   'Replicate original performance without extensive training resources']}}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_table = \"\"\"| Openness level | What's open? | Impact on retraining/modifying |\n",
        "| --- | --- | --- |\n",
        "| Fully Open | Weights, architecture, code, (sometimes) training data | Easiest: full flexibility for fine-tuning, domain adaptation, and safe on-prem deployment |\n",
        "| Weights Released | Weights + architecture | Moderate: fine-tuning possible, but limited visibility into training data; some commercial restrictions may apply |\n",
        "| Architecture Only | Architecture description only | Hardest: you must train from scratch; extremely costly and slow for domain adaptation |\n",
        "\"\"\"\n",
        "print(comparison_table)\n"
      ],
      "metadata": {
        "id": "be6GNRG0bRfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538403a5-9083-457c-9772-9c899f613857"
      },
      "id": "be6GNRG0bRfG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Openness level | What's open? | Impact on retraining/modifying |\n",
            "| --- | --- | --- |\n",
            "| Fully Open | Weights, architecture, code, (sometimes) training data | Easiest: full flexibility for fine-tuning, domain adaptation, and safe on-prem deployment |\n",
            "| Weights Released | Weights + architecture | Moderate: fine-tuning possible, but limited visibility into training data; some commercial restrictions may apply |\n",
            "| Architecture Only | Architecture description only | Hardest: you must train from scratch; extremely costly and slow for domain adaptation |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparative_paragraph = \"\"\"Fully open-source models provide the highest level of transparency and control, giving users access to code, architecture, and weights, which makes fine-tuning and domain adaptation straightforward. Models with released weights offer a middle ground: users can run and adapt the model, but they lack insight into the original training data and may face licensing constraints. Architecture-only releases offer conceptual value but little practical utility, since the absence of weights requires costly training from scratch. As openness decreases, the effort, resources, and complexity required to adapt a model increase significantly. Therefore, the chosen openness level directly influences feasibility, cost, and compliance in specialized domains.\"\"\"\n",
        "print(comparative_paragraph)\n"
      ],
      "metadata": {
        "id": "59ywO8q3bmLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22361ab3-1e5a-460e-a813-c1de050764bb"
      },
      "id": "59ywO8q3bmLZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fully open-source models provide the highest level of transparency and control, giving users access to code, architecture, and weights, which makes fine-tuning and domain adaptation straightforward. Models with released weights offer a middle ground: users can run and adapt the model, but they lack insight into the original training data and may face licensing constraints. Architecture-only releases offer conceptual value but little practical utility, since the absence of weights requires costly training from scratch. As openness decreases, the effort, resources, and complexity required to adapt a model increase significantly. Therefore, the chosen openness level directly influences feasibility, cost, and compliance in specialized domains.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthcare_prompt_answer = \"\"\"In healthcare, only fully open or weights-released models are suitable for retraining on clinical data because they can be fine-tuned locally while maintaining strict privacy and compliance requirements. Architecture-only models are impractical since they require prohibitively expensive training from scratch.\"\"\"\n",
        "print(healthcare_prompt_answer)\n"
      ],
      "metadata": {
        "id": "5o5njZhWbsI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dab6af7-5546-4bb5-f8bb-d075f0ebf2ee"
      },
      "id": "5o5njZhWbsI6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In healthcare, only fully open or weights-released models are suitable for retraining on clinical data because they can be fine-tuned locally while maintaining strict privacy and compliance requirements. Architecture-only models are impractical since they require prohibitively expensive training from scratch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c876b3f",
      "metadata": {
        "id": "6c876b3f"
      },
      "source": [
        "## Exercise 2: License Check for SaaS Use\n",
        "**Use:** HF model pages; permissive vs. copyleft; commercial clauses; restrictions (MAU caps, attribution, export controls).\n",
        "\n",
        "**Step-by-step**\n",
        "1) Select two HF models (e.g., Mistral-7B-Instruct, Llama-2-7b-chat-hf) and note URLs.  \n",
        "2) Locate the License field and copy the name.  \n",
        "3) Determine if commercial use is allowed/restricted/prohibited; note conditions.  \n",
        "4) Identify extra restrictions (MAU caps, attribution, export/geography).  \n",
        "5) Build the markdown checklist with your findings.\n",
        "\n",
        "**Deliverables:** model names + URLs + completed checklist."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "license_checklist = [\n",
        "    {\n",
        "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        \"url\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        \"license\": \"Apache 2.0\",\n",
        "        \"commercial_use\": \"Yes\",\n",
        "        \"restrictions\": [\n",
        "            \"Requires preservation of Apache 2.0 NOTICE file\",\n",
        "            \"No major commercial restrictions (permissive license)\"\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "        \"url\": \"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\",\n",
        "        \"license\": \"Llama 2 Community License\",\n",
        "        \"commercial_use\": \"Conditional\",\n",
        "        \"restrictions\": [\n",
        "            \"Cannot use the model to compete with Meta products\",\n",
        "            \"Must comply with Responsible Use Guidelines\",\n",
        "            \"Attribution required\",\n",
        "            \"Potential export/geography restrictions\"\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "license_checklist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZr7P2yYccjx",
        "outputId": "2dbdb248-4e43-46cb-d58b-aa7d8a148ce6"
      },
      "id": "UZr7P2yYccjx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model': 'mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'url': 'https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'license': 'Apache 2.0',\n",
              "  'commercial_use': 'Yes',\n",
              "  'restrictions': ['Requires preservation of Apache 2.0 NOTICE file',\n",
              "   'No major commercial restrictions (permissive license)']},\n",
              " {'model': 'meta-llama/Llama-2-7b-chat-hf',\n",
              "  'url': 'https://huggingface.co/meta-llama/Llama-2-7b-chat-hf',\n",
              "  'license': 'Llama 2 Community License',\n",
              "  'commercial_use': 'Conditional',\n",
              "  'restrictions': ['Cannot use the model to compete with Meta products',\n",
              "   'Must comply with Responsible Use Guidelines',\n",
              "   'Attribution required',\n",
              "   'Potential export/geography restrictions']}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 – Mistral-7B-Instruct-v0.3\n",
        "\n",
        "Type of license:\n",
        "Apache 2.0 (permissive)\n",
        "\n",
        "Commercial use allowed:\n",
        "Yes\n",
        "\n",
        "Restrictions:\n",
        "\n",
        "* Must preserve the Apache 2.0 NOTICE file\n",
        "\n",
        "* No major commercial restrictions (standard permissive license)\n",
        "\n",
        "Model 2 – Llama-2-7b-chat-hf\n",
        "\n",
        "Type of license:\n",
        "Llama 2 Community License\n",
        "\n",
        "Commercial use allowed:\n",
        "Conditional\n",
        "\n",
        "Restrictions:\n",
        "\n",
        "* Cannot use the model to compete with Meta products\n",
        "\n",
        "* Must follow the Responsible Use Guidelines\n",
        "\n",
        "* Attribution required\n",
        "\n",
        "* Possible export/geographic limitations"
      ],
      "metadata": {
        "id": "VBDq8_HHctYo"
      },
      "id": "VBDq8_HHctYo"
    },
    {
      "cell_type": "markdown",
      "id": "710648ba",
      "metadata": {
        "id": "710648ba"
      },
      "source": [
        "## Exercise 3: LLM Matchmaker Challenge\n",
        "**Use:** CPU inference, low-end laptops, multilingual needs; HF filters; size <=7B; benchmarks (BoolQ, GSM8K, FLORES-200).\n",
        "\n",
        "**Step-by-step**\n",
        "1) Analyze team needs (LegalTech CPU logic; EdTech math/logic low-end; Global NGO multilingual >=5 langs).  \n",
        "2) Apply HF filters (cpu/quantized, logic/math/multilingual tags, size <=7B).  \n",
        "3) List 3?5 candidates per team with params/arch/quantization/benchmarks.  \n",
        "4) Compare top 2 per team and pick the best model with justification.  \n",
        "5) Fill the table with your picks.\n",
        "\n",
        "**Deliverables:** filter summary + filled picks table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filters_by_team = {\n",
        "    \"LegalTech\": [\n",
        "        \"text-generation\",\n",
        "        \"cpu-inference\",\n",
        "        \"GGUF or quantized\",\n",
        "        \"logic/BoolQ benchmark\",\n",
        "        \"<=7B parameters\"\n",
        "    ],\n",
        "    \"EdTech\": [\n",
        "        \"math/GSM8K tag\",\n",
        "        \"cpu or quantized\",\n",
        "        \"<=7B (prefer <=4B)\",\n",
        "        \"instruction-tuned\"\n",
        "    ],\n",
        "    \"Global NGO\": [\n",
        "        \"multilingual/FLORES-200 tag\",\n",
        "        \"cpu or GGUF quantized\",\n",
        "        \"<=7B parameters\",\n",
        "        \"supports ≥5 languages\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "filters_by_team\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEGxSPS_dM_o",
        "outputId": "50fadd84-3d77-4605-cded-294bda278934"
      },
      "id": "YEGxSPS_dM_o",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LegalTech': ['text-generation',\n",
              "  'cpu-inference',\n",
              "  'GGUF or quantized',\n",
              "  'logic/BoolQ benchmark',\n",
              "  '<=7B parameters'],\n",
              " 'EdTech': ['math/GSM8K tag',\n",
              "  'cpu or quantized',\n",
              "  '<=7B (prefer <=4B)',\n",
              "  'instruction-tuned'],\n",
              " 'Global NGO': ['multilingual/FLORES-200 tag',\n",
              "  'cpu or GGUF quantized',\n",
              "  '<=7B parameters',\n",
              "  'supports ≥5 languages']}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidates_by_team = {\n",
        "    \"LegalTech\": [\n",
        "        {\n",
        "            \"model\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "            \"params_b\": \"7B\",\n",
        "            \"arch\": \"Transformer (Mistral architecture)\",\n",
        "            \"optimization\": \"Available in GGUF for CPU; quantized Q4_K_M/Q5_K_M\",\n",
        "            \"benchmarks\": \"Strong on BoolQ, general reasoning\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"google/gemma-2b-it\",\n",
        "            \"params_b\": \"2B\",\n",
        "            \"arch\": \"Gemma Transformer\",\n",
        "            \"optimization\": \"Very CPU-friendly; GGUF/Q4 available\",\n",
        "            \"benchmarks\": \"Good logical reasoning for size\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"TheBloke/Llama-3-8B-Instruct-GGUF (8B but quantized fits CPU)\",\n",
        "            \"params_b\": \"8B (effective <7B due to quantization constraints)\",\n",
        "            \"arch\": \"Llama 3\",\n",
        "            \"optimization\": \"GGUF, Q4_K_M\",\n",
        "            \"benchmarks\": \"High accuracy on BoolQ and legal-style QA\"\n",
        "        },\n",
        "    ],\n",
        "\n",
        "    \"EdTech\": [\n",
        "        {\n",
        "            \"model\": \"Qwen/Qwen2-1.5B-Instruct\",\n",
        "            \"params_b\": \"1.5B\",\n",
        "            \"arch\": \"Qwen2 Transformer\",\n",
        "            \"optimization\": \"Quantized GGUF available\",\n",
        "            \"benchmarks\": \"Strong GSM8K for small size\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"google/gemma-2b-it\",\n",
        "            \"params_b\": \"2B\",\n",
        "            \"arch\": \"Gemma Transformer\",\n",
        "            \"optimization\": \"Lightweight, CPU-ready\",\n",
        "            \"benchmarks\": \"Good GSM8K math reasoning\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"deepseek-ai/deepseek-math-7b\",\n",
        "            \"params_b\": \"7B\",\n",
        "            \"arch\": \"DeepSeek Math\",\n",
        "            \"optimization\": \"GGUF quantized versions exist\",\n",
        "            \"benchmarks\": \"High GSM8K accuracy for math tutoring\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"Mistral-7B-Instruct-v0.3\",\n",
        "            \"params_b\": \"7B\",\n",
        "            \"arch\": \"Mistral\",\n",
        "            \"optimization\": \"GGUF optimized\",\n",
        "            \"benchmarks\": \"Decent GSM8K for general reasoning\"\n",
        "        },\n",
        "    ],\n",
        "\n",
        "    \"Global NGO\": [\n",
        "        {\n",
        "            \"model\": \"Qwen/Qwen2-7B-Instruct\",\n",
        "            \"params_b\": \"7B\",\n",
        "            \"arch\": \"Qwen2\",\n",
        "            \"optimization\": \"GGUF, CPU-ready\",\n",
        "            \"benchmarks\": \"Top-tier multilingual (FLORES-200)\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"google/mt5-small\",\n",
        "            \"params_b\": \"300M\",\n",
        "            \"arch\": \"mT5\",\n",
        "            \"optimization\": \"CPU friendly; not quantized\",\n",
        "            \"benchmarks\": \"Strong multilingual baseline\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"TheBloke/XLM-RoBERTa-Base-GGUF\",\n",
        "            \"params_b\": \"270M\",\n",
        "            \"arch\": \"XLM-R\",\n",
        "            \"optimization\": \"GGUF optimized for CPU\",\n",
        "            \"benchmarks\": \"Excellent cross-lingual understanding\"\n",
        "        },\n",
        "        {\n",
        "            \"model\": \"facebook/mbart-large-50\",\n",
        "            \"params_b\": \"610M\",\n",
        "            \"arch\": \"mBART\",\n",
        "            \"optimization\": \"Runs on CPU; not GGUF but efficient\",\n",
        "            \"benchmarks\": \"Very strong translation across 50 languages\"\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "candidates_by_team\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9eTBn-OdapN",
        "outputId": "048d1250-9e76-4b1a-a0d2-7a341d9a94d7"
      },
      "id": "l9eTBn-OdapN",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LegalTech': [{'model': 'mistralai/Mistral-7B-Instruct-v0.3',\n",
              "   'params_b': '7B',\n",
              "   'arch': 'Transformer (Mistral architecture)',\n",
              "   'optimization': 'Available in GGUF for CPU; quantized Q4_K_M/Q5_K_M',\n",
              "   'benchmarks': 'Strong on BoolQ, general reasoning'},\n",
              "  {'model': 'google/gemma-2b-it',\n",
              "   'params_b': '2B',\n",
              "   'arch': 'Gemma Transformer',\n",
              "   'optimization': 'Very CPU-friendly; GGUF/Q4 available',\n",
              "   'benchmarks': 'Good logical reasoning for size'},\n",
              "  {'model': 'TheBloke/Llama-3-8B-Instruct-GGUF (8B but quantized fits CPU)',\n",
              "   'params_b': '8B (effective <7B due to quantization constraints)',\n",
              "   'arch': 'Llama 3',\n",
              "   'optimization': 'GGUF, Q4_K_M',\n",
              "   'benchmarks': 'High accuracy on BoolQ and legal-style QA'}],\n",
              " 'EdTech': [{'model': 'Qwen/Qwen2-1.5B-Instruct',\n",
              "   'params_b': '1.5B',\n",
              "   'arch': 'Qwen2 Transformer',\n",
              "   'optimization': 'Quantized GGUF available',\n",
              "   'benchmarks': 'Strong GSM8K for small size'},\n",
              "  {'model': 'google/gemma-2b-it',\n",
              "   'params_b': '2B',\n",
              "   'arch': 'Gemma Transformer',\n",
              "   'optimization': 'Lightweight, CPU-ready',\n",
              "   'benchmarks': 'Good GSM8K math reasoning'},\n",
              "  {'model': 'deepseek-ai/deepseek-math-7b',\n",
              "   'params_b': '7B',\n",
              "   'arch': 'DeepSeek Math',\n",
              "   'optimization': 'GGUF quantized versions exist',\n",
              "   'benchmarks': 'High GSM8K accuracy for math tutoring'},\n",
              "  {'model': 'Mistral-7B-Instruct-v0.3',\n",
              "   'params_b': '7B',\n",
              "   'arch': 'Mistral',\n",
              "   'optimization': 'GGUF optimized',\n",
              "   'benchmarks': 'Decent GSM8K for general reasoning'}],\n",
              " 'Global NGO': [{'model': 'Qwen/Qwen2-7B-Instruct',\n",
              "   'params_b': '7B',\n",
              "   'arch': 'Qwen2',\n",
              "   'optimization': 'GGUF, CPU-ready',\n",
              "   'benchmarks': 'Top-tier multilingual (FLORES-200)'},\n",
              "  {'model': 'google/mt5-small',\n",
              "   'params_b': '300M',\n",
              "   'arch': 'mT5',\n",
              "   'optimization': 'CPU friendly; not quantized',\n",
              "   'benchmarks': 'Strong multilingual baseline'},\n",
              "  {'model': 'TheBloke/XLM-RoBERTa-Base-GGUF',\n",
              "   'params_b': '270M',\n",
              "   'arch': 'XLM-R',\n",
              "   'optimization': 'GGUF optimized for CPU',\n",
              "   'benchmarks': 'Excellent cross-lingual understanding'},\n",
              "  {'model': 'facebook/mbart-large-50',\n",
              "   'params_b': '610M',\n",
              "   'arch': 'mBART',\n",
              "   'optimization': 'Runs on CPU; not GGUF but efficient',\n",
              "   'benchmarks': 'Very strong translation across 50 languages'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matchmaker_table = \"\"\"| Team | Needs | Your Pick |\n",
        "| --- | --- | --- |\n",
        "| LegalTech | Fast model for logic-heavy chatbot on CPU | Mistral-7B-Instruct-v0.3 (GGUF quantized) |\n",
        "| EdTech | Logic/math-focused LLM on low-end laptops | Qwen2-1.5B-Instruct |\n",
        "| Global NGO | Model that speaks 5+ languages well | Qwen2-7B-Instruct |\n",
        "\"\"\"\n",
        "print(matchmaker_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1tTgQNmdlLj",
        "outputId": "59b5af0d-c440-4018-af3c-758255996489"
      },
      "id": "Z1tTgQNmdlLj",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Team | Needs | Your Pick |\n",
            "| --- | --- | --- |\n",
            "| LegalTech | Fast model for logic-heavy chatbot on CPU | Mistral-7B-Instruct-v0.3 (GGUF quantized) |\n",
            "| EdTech | Logic/math-focused LLM on low-end laptops | Qwen2-1.5B-Instruct |\n",
            "| Global NGO | Model that speaks 5+ languages well | Qwen2-7B-Instruct |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7925001c",
      "metadata": {
        "id": "7925001c"
      },
      "source": [
        "## Exercise 4: Local Readiness Audit\n",
        "**Use:** RAM/disk/OS; llama.cpp requirements (AVX/SSE, cmake/make/gcc/clang); quantized formats (GGUF).\n",
        "\n",
        "**Step-by-step**\n",
        "1) Gather system specs (RAM, free disk, OS type/version).  \n",
        "2) Fill the audit table and mark ?/?.  \n",
        "3) Check llama.cpp readiness (instruction sets, compilers, build tools).  \n",
        "4) Identify upgrade needs for each ?.\n",
        "\n",
        "**Deliverables:** filled table + upgrade summary."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_specs = {\n",
        "    \"ram_gb\": \"Unknown (fill after checking system info)\",\n",
        "    \"free_disk_gb\": \"Unknown (check available storage)\",\n",
        "    \"os\": \"Unknown (Windows / macOS / Linux + version)\",\n",
        "}\n",
        "\n",
        "system_specs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9srpxBFdzGx",
        "outputId": "325548fc-26ba-4687-c350-357d647000d7"
      },
      "id": "E9srpxBFdzGx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ram_gb': 'Unknown (fill after checking system info)',\n",
              " 'free_disk_gb': 'Unknown (check available storage)',\n",
              " 'os': 'Unknown (Windows / macOS / Linux + version)'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readiness_table = \"\"\"| Requirement | Your System Specs | Meets Requirement? |\n",
        "| --- | --- | --- |\n",
        "| RAM (>= 16 GB) | Unknown | ? |\n",
        "| Free Disk Space (>= 40 GB) | Unknown | ? |\n",
        "| OS (Linux/WSL2) | Unknown | ? |\"\"\"\n",
        "print(readiness_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhALnCULeEiJ",
        "outputId": "9dca13af-b712-4e15-8955-a93862d8bb98"
      },
      "id": "UhALnCULeEiJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Requirement | Your System Specs | Meets Requirement? |\n",
            "| --- | --- | --- |\n",
            "| RAM (>= 16 GB) | Unknown | ? |\n",
            "| Free Disk Space (>= 40 GB) | Unknown | ? |\n",
            "| OS (Linux/WSL2) | Unknown | ? |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_cpp_readiness = {\n",
        "    \"cpu_instruction_support\": \"Unknown (check for AVX2 or higher)\",\n",
        "    \"tooling\": [\n",
        "        \"Unknown (requires CMake installed)\",\n",
        "        \"Unknown (requires GCC or Clang compilers)\"\n",
        "    ],\n",
        "    \"other_requirements\": \"Need ability to compile llama.cpp locally; GGUF support required\",\n",
        "}\n",
        "\n",
        "llama_cpp_readiness\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ahoc-aPeTZl",
        "outputId": "20c2b2fd-efc2-4129-8db3-710938cdfd57"
      },
      "id": "2ahoc-aPeTZl",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cpu_instruction_support': 'Unknown (check for AVX2 or higher)',\n",
              " 'tooling': ['Unknown (requires CMake installed)',\n",
              "  'Unknown (requires GCC or Clang compilers)'],\n",
              " 'other_requirements': 'Need ability to compile llama.cpp locally; GGUF support required'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upgrade_actions = [\n",
        "    \"Install required build tools (CMake + GCC/Clang) and enable AVX2-capable CPU if available\",\n",
        "    \"Free additional disk space or add external storage for model quantization and caching\"\n",
        "]\n",
        "\n",
        "upgrade_actions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDY7LPCdecVi",
        "outputId": "e1e038e8-9a56-47ea-ec56-2471ceec7595"
      },
      "id": "nDY7LPCdecVi",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Install required build tools (CMake + GCC/Clang) and enable AVX2-capable CPU if available',\n",
              " 'Free additional disk space or add external storage for model quantization and caching']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d811cf86",
      "metadata": {
        "id": "d811cf86"
      },
      "source": [
        "## Exercise 5: Benchmark-Based Model Explorer\n",
        "**Use:** Open LLM Leaderboard; HellaSwag and MMLU scores; license types; use-case mapping.\n",
        "\n",
        "**Step-by-step**\n",
        "1) Pick three models from the leaderboard with different strengths (high HellaSwag, high MMLU, balanced).  \n",
        "2) Record HellaSwag, MMLU, license, and ideal use case.  \n",
        "3) Fill the comparison table.  \n",
        "4) Optional: 1?2 sentence reflection on why benchmarks matter.  \n",
        "5) Quiz-style reflection: write 3 short Q&A items about choosing models for different constraints.\n",
        "\n",
        "**Deliverables:** model list + filled table + quiz-style reflection (+ optional reflection paragraph)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard_models = [\n",
        "    {\n",
        "        \"model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "        \"url\": \"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "        \"hellaswag\": \"≈87%\",\n",
        "        \"mmlu\": \"≈68%\",\n",
        "        \"license\": \"Meta Llama 3 License\",\n",
        "        \"ideal_use_case\": \"Strong commonsense reasoning, legal/logic chatbots, multi-step QA\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"Qwen/Qwen2-7B-Instruct\",\n",
        "        \"url\": \"https://huggingface.co/Qwen/Qwen2-7B-Instruct\",\n",
        "        \"hellaswag\": \"≈85%\",\n",
        "        \"mmlu\": \"≈78%\",\n",
        "        \"license\": \"Apache 2.0\",\n",
        "        \"ideal_use_case\": \"High-level academic reasoning, tutoring, analytic tasks\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        \"url\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        \"hellaswag\": \"≈84%\",\n",
        "        \"mmlu\": \"≈70%\",\n",
        "        \"license\": \"Apache 2.0\",\n",
        "        \"ideal_use_case\": \"Generalist assistant, multilingual tasks, everyday instruction following\"\n",
        "    },\n",
        "]\n",
        "\n",
        "leaderboard_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggSl4c16erH5",
        "outputId": "bb11fc01-80b6-4755-8e11-04338c485c80"
      },
      "id": "ggSl4c16erH5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model': 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
              "  'url': 'https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct',\n",
              "  'hellaswag': '≈87%',\n",
              "  'mmlu': '≈68%',\n",
              "  'license': 'Meta Llama 3 License',\n",
              "  'ideal_use_case': 'Strong commonsense reasoning, legal/logic chatbots, multi-step QA'},\n",
              " {'model': 'Qwen/Qwen2-7B-Instruct',\n",
              "  'url': 'https://huggingface.co/Qwen/Qwen2-7B-Instruct',\n",
              "  'hellaswag': '≈85%',\n",
              "  'mmlu': '≈78%',\n",
              "  'license': 'Apache 2.0',\n",
              "  'ideal_use_case': 'High-level academic reasoning, tutoring, analytic tasks'},\n",
              " {'model': 'mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'url': 'https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'hellaswag': '≈84%',\n",
              "  'mmlu': '≈70%',\n",
              "  'license': 'Apache 2.0',\n",
              "  'ideal_use_case': 'Generalist assistant, multilingual tasks, everyday instruction following'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_table = \"\"\"| Model Name | HellaSwag Score | MMLU Score | License Type | Ideal Use Case |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| Meta-Llama-3-8B-Instruct | ≈87% | ≈68% | Meta Llama 3 License | Strong commonsense reasoning, legal/logic chatbots |\n",
        "| Qwen2-7B-Instruct | ≈85% | ≈78% | Apache 2.0 | High-level academic reasoning, tutoring, analytic tasks |\n",
        "| Mistral-7B-Instruct-v0.3 | ≈84% | ≈70% | Apache 2.0 | General-purpose assistant, multilingual instruction tasks |\n",
        "\"\"\"\n",
        "print(benchmark_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnW6ZjEQe0wi",
        "outputId": "4cf78878-ffe5-44d8-a2bc-cc303dfd853c"
      },
      "id": "dnW6ZjEQe0wi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model Name | HellaSwag Score | MMLU Score | License Type | Ideal Use Case |\n",
            "| --- | --- | --- | --- | --- |\n",
            "| Meta-Llama-3-8B-Instruct | ≈87% | ≈68% | Meta Llama 3 License | Strong commonsense reasoning, legal/logic chatbots |\n",
            "| Qwen2-7B-Instruct | ≈85% | ≈78% | Apache 2.0 | High-level academic reasoning, tutoring, analytic tasks |\n",
            "| Mistral-7B-Instruct-v0.3 | ≈84% | ≈70% | Apache 2.0 | General-purpose assistant, multilingual instruction tasks |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "772135e7",
      "metadata": {
        "id": "772135e7"
      },
      "source": [
        "### Optional reflection\n",
        "1?2 sentences on why benchmarks?not hype?should guide model choice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_reflection = [\n",
        "    {\n",
        "        \"question\": \"Which benchmark should you check when choosing a model for math tutoring?\",\n",
        "        \"answer\": \"GSM8K, because it measures mathematical reasoning and step-by-step problem solving.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What benchmark is most useful when selecting a model for logic-heavy legal chatbots?\",\n",
        "        \"answer\": \"HellaSwag or BoolQ, since they evaluate commonsense reasoning and logical inference.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What’s the first thing you check when selecting a model for a multilingual NGO project?\",\n",
        "        \"answer\": \"Whether the model scores well on FLORES-200 or supports many languages natively.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "quiz_reflection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1e5Hi2_fAqk",
        "outputId": "57e8ea95-a2a7-4f60-bb00-3f9927518297"
      },
      "id": "C1e5Hi2_fAqk",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'Which benchmark should you check when choosing a model for math tutoring?',\n",
              "  'answer': 'GSM8K, because it measures mathematical reasoning and step-by-step problem solving.'},\n",
              " {'question': 'What benchmark is most useful when selecting a model for logic-heavy legal chatbots?',\n",
              "  'answer': 'HellaSwag or BoolQ, since they evaluate commonsense reasoning and logical inference.'},\n",
              " {'question': 'What’s the first thing you check when selecting a model for a multilingual NGO project?',\n",
              "  'answer': 'Whether the model scores well on FLORES-200 or supports many languages natively.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7079932",
      "metadata": {
        "id": "b7079932"
      },
      "source": [
        "## Exercise 6: Cloud vs. Local Deployment Plan\n",
        "**Use:** local vs. cloud cost/latency/scalability/security/maintenance; optional Colab timing.\n",
        "\n",
        "**Step-by-step**\n",
        "1) Draft 5 bullets pairing local vs. cloud pros/cons.  \n",
        "2) Optional: run a 7B model on Colab; note model and response time.  \n",
        "3) Summarize Colab observation if you ran it.\n",
        "\n",
        "**Deliverables:** 5 bullets; optional Colab report (model + time)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pros_and_cons = [\n",
        "    \"Local deployment offers lower latency and full data privacy, but requires strong hardware and manual maintenance.\",\n",
        "    \"Cloud deployment scales easily for many users, but introduces ongoing compute costs.\",\n",
        "    \"Local inference avoids vendor lock-in, while cloud solutions rely heavily on provider availability and pricing.\",\n",
        "    \"Cloud GPUs handle large models effortlessly, whereas local machines may require heavy quantization.\",\n",
        "    \"Local setups give full offline control, while cloud deployments provide easier updates and monitoring.\"\n",
        "]\n",
        "\n",
        "pros_and_cons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u7YCUEMfM7-",
        "outputId": "60b16db6-e33e-44c9-94e9-f4b5bf81ea12"
      },
      "id": "_u7YCUEMfM7-",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Local deployment offers lower latency and full data privacy, but requires strong hardware and manual maintenance.',\n",
              " 'Cloud deployment scales easily for many users, but introduces ongoing compute costs.',\n",
              " 'Local inference avoids vendor lock-in, while cloud solutions rely heavily on provider availability and pricing.',\n",
              " 'Cloud GPUs handle large models effortlessly, whereas local machines may require heavy quantization.',\n",
              " 'Local setups give full offline control, while cloud deployments provide easier updates and monitoring.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colab_run = {\n",
        "    \"model_tested\": \"Unknown (fill after running in Colab)\",\n",
        "    \"response_time_seconds\": \"Unknown\",\n",
        "    \"notes\": \"Run a 7B GGUF or HF model and record the first-token latency or full response time.\",\n",
        "}\n",
        "\n",
        "colab_run\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO_1m9zZfUgX",
        "outputId": "eb69db28-f9cd-4942-fdc7-ea91b2c700f6"
      },
      "id": "QO_1m9zZfUgX",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_tested': 'Unknown (fill after running in Colab)',\n",
              " 'response_time_seconds': 'Unknown',\n",
              " 'notes': 'Run a 7B GGUF or HF model and record the first-token latency or full response time.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}